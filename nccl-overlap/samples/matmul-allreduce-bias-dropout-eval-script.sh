#mpirun -np 2 -x LD_LIBRARY_PATH="../build/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH" -x NCCL_MIN_NCHANNELS=16 -x NCCL_MAX_NCHANNELS=16 -x NCCL_NTHREADS=512 -x NCCL_BUFFSIZE=4194304 ./matmul-allreduce > matmul-results-2-gpus-16-channels.txt
#mpirun -np 4 -x LD_LIBRARY_PATH="../build/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH" -x NCCL_MIN_NCHANNELS=16 -x NCCL_MAX_NCHANNELS=16 -x NCCL_NTHREADS=512 -x NCCL_BUFFSIZE=4194304 ./matmul-allreduce > matmul-results-4-gpus-16-channels.txt
mpirun -np 16 -x LD_LIBRARY_PATH="../build/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH"  -x NCCL_MIN_NCHANNELS=12 -x NCCL_MAX_NCHANNELS=12 -x NCCL_NTHREADS=512 -x NCCL_BUFFSIZE=3145728 ./matmul-allreduce-bias-dropout-layernorm > matmul-allreduce-bias-dropout-results-16-gpus-12-channels-3M-buffsize.txt
#mpirun -np 16 -x LD_LIBRARY_PATH="../build/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH" -x NCCL_MIN_NCHANNELS=16 -x NCCL_MAX_NCHANNELS=16 -x NCCL_NTHREADS=512 -x NCCL_BUFFSIZE=4194304 ./matmul-allreduce > matmul-results-16-gpus-16-channels.txt
mpirun -np 16 -x LD_LIBRARY_PATH="../build/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH"  -x NCCL_MIN_NCHANNELS=12 -x NCCL_MAX_NCHANNELS=12 -x NCCL_NTHREADS=512 -x NCCL_BUFFSIZE=1572864 ./matmul-allreduce-bias-dropout-layernorm > matmul-allreduce-bias-dropout-results-16-gpus-12-channels-1.5M-buffsize.txt
mpirun -np 16 -x LD_LIBRARY_PATH="../build/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH"  -x NCCL_MIN_NCHANNELS=12 -x NCCL_MAX_NCHANNELS=12 -x NCCL_NTHREADS=512 -x NCCL_BUFFSIZE=6291456 ./matmul-allreduce-bias-dropout-layernorm > matmul-allreduce-bias-dropout-results-16-gpus-12-channels-6M-buffsize.txt
mpirun -np 16 -x LD_LIBRARY_PATH="../build/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH"  -x NCCL_MIN_NCHANNELS=12 -x NCCL_MAX_NCHANNELS=12 -x NCCL_NTHREADS=512 -x NCCL_BUFFSIZE=768000 ./matmul-allreduce-bias-dropout-layernorm > matmul-allreduce-bias-dropout-results-16-gpus-12-channels-750K-buffsize.txt
mpirun -np 16 -x LD_LIBRARY_PATH="../build/lib:/usr/local/cuda/lib64:$LD_LIBRARY_PATH"  -x NCCL_MIN_NCHANNELS=12 -x NCCL_MAX_NCHANNELS=12 -x NCCL_NTHREADS=512 -x NCCL_BUFFSIZE=384000 ./matmul-allreduce-bias-dropout-layernorm > matmul-allreduce-bias-dropout-results-16-gpus-12-channels-375K-buffsize.txt
